#!/usr/bin/env python3
"""
main_pipeline.py
CNN-LSTM íƒœì–‘ê´‘ ë°œì „ ê¸°ë°˜ ì „ë ¥ ìˆ˜ìš” ì˜ˆì¸¡ ì „ì²´ ì‹¤í–‰ íŒŒì´í”„ë¼ì¸
"""

import os
import sys
import argparse
import json
from datetime import datetime
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import warnings
import numpy as np
warnings.filterwarnings('ignore')

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
from data_loader import SolarDataLoader
from feature_engineer import SolarFeatureEngineer
from cnn_lstm_model import CNNLSTMBuilder, ModelEnsemble
from model_trainer import ModelTrainer, HyperparameterTuner
from visualizer import ResultVisualizer

class SolarPowerPredictionPipeline:
    """íƒœì–‘ê´‘ ë°œì „ ê¸°ë°˜ ì „ë ¥ ìˆ˜ìš” ì˜ˆì¸¡ ì „ì²´ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, config=None):
        """
        íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        
        Args:
            config (dict): ì„¤ì • ë”•ì…”ë„ˆë¦¬
        """
        self.config = config or self._default_config()
        self.loader = SolarDataLoader()
        self.engineer = SolarFeatureEngineer()
        self.builder = CNNLSTMBuilder()
        self.trainer = ModelTrainer()
        self.visualizer = None  # ë‚˜ì¤‘ì— ì´ˆê¸°í™”
        
        self.processed_data = None
        self.model = None
        self.results = {}
        
        # ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
        self.output_dir = self.config.get('output_dir', 'results')
        os.makedirs(self.output_dir, exist_ok=True)
    
    def _default_config(self):
        """ê¸°ë³¸ ì„¤ì • ë°˜í™˜"""
        return {
            # ë°ì´í„° ì„¤ì •
            'generation_file': 'Plant_1_Generation_Data.csv',
            'weather_file': 'Plant_1_Weather_Sensor_Data.csv',
            'use_synthetic_data': False,
            
            # íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ì„¤ì •
            'sequence_length': 24,
            'feature_selection_method': 'correlation',
            'normalization_method': 'minmax',
            
            # ëª¨ë¸ ì„¤ì •
            'model_type': 'advanced',  # 'basic', 'advanced', 'transformer'
            'cnn_filters': [64, 64, 32],
            'lstm_units': [128, 64],
            'dense_units': [128, 64, 32],
            'dropout_rate': 0.3,
            'use_attention': True,
            'use_bidirectional': True,
            
            # í•™ìŠµ ì„¤ì •
            'epochs': 100,
            'batch_size': 32,
            'learning_rate': 0.001,
            'optimizer': 'adam',
            'loss': 'huber',
            'early_stopping_patience': 15,
            
            # ë°ì´í„° ë¶„í•  ì„¤ì •
            'train_ratio': 0.7,
            'val_ratio': 0.15,
            'test_ratio': 0.15,
            'shuffle': False,  # ì‹œê³„ì—´ ë°ì´í„°ì´ë¯€ë¡œ False
            
            # ê¸°íƒ€ ì„¤ì •
            'random_seed': 42,
            'verbose': 1,
            'save_model': True,
            'save_results': True,
            'output_dir': 'results',
            'run_cross_validation': False,
            'run_hyperparameter_tuning': False
        }
    
    def load_config(self, config_file):
        """
        ì„¤ì • íŒŒì¼ ë¡œë“œ
        
        Args:
            config_file (str): ì„¤ì • íŒŒì¼ ê²½ë¡œ
        """
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                loaded_config = json.load(f)
            
            # ê¸°ë³¸ ì„¤ì •ê³¼ ë³‘í•©
            self.config.update(loaded_config)
            print(f"âœ… ì„¤ì • íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {config_file}")
            
        except Exception as e:
            print(f"âŒ ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("ğŸ’¡ ê¸°ë³¸ ì„¤ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    def save_config(self, config_file=None):
        """
        í˜„ì¬ ì„¤ì • ì €ì¥
        
        Args:
            config_file (str): ì €ì¥í•  íŒŒì¼ëª…
        """
        if config_file is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            config_file = os.path.join(self.output_dir, f'config_{timestamp}.json')
        
        try:
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(self.config, f, indent=2, ensure_ascii=False)
            print(f"âœ… ì„¤ì • íŒŒì¼ ì €ì¥: {config_file}")
            
        except Exception as e:
            print(f"âŒ ì„¤ì • íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def run_data_pipeline(self):
        """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
        print("ğŸš€ ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        print("="*60)
        
        # 1. ë°ì´í„° ë¡œë“œ
        if self.config['use_synthetic_data']:
            print("ğŸ“Š í•©ì„± ë°ì´í„° ì‚¬ìš©")
            gen_df, weather_df = self.loader.generate_synthetic_data()
            processed_df = self.loader.merge_data(
                self.loader.aggregate_hourly_generation(gen_df),
                self.loader.aggregate_hourly_weather(weather_df)
            )
            processed_df = self.loader.filter_daytime_data(processed_df)
        else:
            processed_df = self.loader.preprocess_pipeline(
                self.config['generation_file'],
                self.config['weather_file']
            )
        
        # 2. íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§
        X, y, features, scalers = self.engineer.feature_engineering_pipeline(
            processed_df,
            sequence_length=self.config['sequence_length'],
            feature_selection_method=self.config['feature_selection_method']
        )
        
        self.processed_data = {
            'X': X,
            'y': y,
            'features': features,
            'scalers': scalers,
            'raw_data': processed_df
        }
        
        print("âœ… ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
        return self.processed_data
    
    def run_model_pipeline(self):
        """ëª¨ë¸ êµ¬ì¶• ë° í•™ìŠµ íŒŒì´í”„ë¼ì¸"""
        print("ğŸ§  ëª¨ë¸ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        print("="*60)
        
        if self.processed_data is None:
            raise ValueError("ë°ì´í„° íŒŒì´í”„ë¼ì¸ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        
        X, y = self.processed_data['X'], self.processed_data['y']
        
        # 1. ë°ì´í„° ë¶„í• 
        X_train, X_val, X_test, y_train, y_val, y_test = self.trainer.prepare_train_data(
            X, y,
            train_ratio=self.config['train_ratio'],
            val_ratio=self.config['val_ratio'],
            test_ratio=self.config['test_ratio'],
            shuffle=self.config['shuffle']
        )
        
        # 2. ëª¨ë¸ êµ¬ì¶•
        input_shape = X.shape[1:]
        
        if self.config['model_type'] == 'basic':
            model = self.builder.build_basic_cnn_lstm(
                input_shape,
                cnn_filters=self.config['cnn_filters'][:2],  # ê¸°ë³¸ ëª¨ë¸ì€ 2ê°œ ë ˆì´ì–´
                lstm_units=self.config['lstm_units'],
                dense_units=self.config['dense_units'],
                dropout_rate=self.config['dropout_rate']
            )
        elif self.config['model_type'] == 'transformer':
            model = self.builder.build_transformer_cnn_lstm(
                input_shape,
                cnn_filters=self.config['cnn_filters'],
                lstm_units=self.config['lstm_units'],
                dense_units=self.config['dense_units'],
                dropout_rate=self.config['dropout_rate']
            )
        else:  # advanced
            model = self.builder.build_advanced_cnn_lstm(
                input_shape,
                cnn_filters=self.config['cnn_filters'],
                lstm_units=self.config['lstm_units'],
                dense_units=self.config['dense_units'],
                dropout_rate=self.config['dropout_rate'],
                use_attention=self.config['use_attention'],
                use_bidirectional=self.config['use_bidirectional']
            )
        
        # 3. ëª¨ë¸ ì»´íŒŒì¼
        model = self.builder.compile_model(
            model,
            optimizer=self.config['optimizer'],
            learning_rate=self.config['learning_rate'],
            loss=self.config['loss']
        )
        
        # 4. ì½œë°± ì„¤ì •
        model_save_path = os.path.join(self.output_dir, 'best_model.h5')
        callbacks = self.builder.create_callbacks(
            patience=self.config['early_stopping_patience'],
            save_path=model_save_path
        )
        
        # 5. ëª¨ë¸ í•™ìŠµ
        history = self.trainer.train_model(
            model, X_train, y_train, X_val, y_val,
            epochs=self.config['epochs'],
            batch_size=self.config['batch_size'],
            callbacks=callbacks,
            verbose=self.config['verbose']
        )
        
        self.model = model
        
        # 6. ëª¨ë¸ í‰ê°€
        metrics, y_true, y_pred = self.trainer.evaluate_model(
            model, X_test, y_test, 
            scalers=self.processed_data['scalers'],
            verbose=self.config['verbose']
        )
        
        self.results = {
            'metrics': metrics,
            'predictions': {
                'y_true': y_true,
                'y_pred': y_pred
            },
            'data_splits': {
                'train_size': len(X_train),
                'val_size': len(X_val),
                'test_size': len(X_test)
            },
            'model_config': self.builder.model_config
        }
        
        print("âœ… ëª¨ë¸ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
        return self.results
    
    def run_evaluation_pipeline(self):
        """í‰ê°€ ë° ì‹œê°í™” íŒŒì´í”„ë¼ì¸"""
        print("ğŸ“Š í‰ê°€ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        print("="*60)
        
        if self.model is None or not self.results:
            raise ValueError("ëª¨ë¸ íŒŒì´í”„ë¼ì¸ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        
        # ì‹œê°í™”ê¸° ì´ˆê¸°í™”
        try:
            from visualizer import ResultVisualizer
            self.visualizer = ResultVisualizer()
        except ImportError:
            print("âš ï¸ visualizer ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì‹œê°í™”ë§Œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
            self.visualizer = None
        
        # 1. í•™ìŠµ ê³¼ì • ì‹œê°í™”
        self.trainer.plot_training_history()
        
        # 2. ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”
        y_true = self.results['predictions']['y_true']
        y_pred = self.results['predictions']['y_pred']
        self.trainer.plot_predictions(y_true, y_pred)
        
        # 3. íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”
        feature_names = self.processed_data['features']
        self.trainer.plot_feature_importance(self.model, feature_names)
        
        # 4. ê³ ê¸‰ ì‹œê°í™” (visualizer ëª¨ë“ˆì´ ìˆëŠ” ê²½ìš°)
        if self.visualizer:
            self.visualizer.plot_comprehensive_results(self.results, self.processed_data)
        
        # 5. êµì°¨ ê²€ì¦ (ì„¤ì •ì—ì„œ í™œì„±í™”ëœ ê²½ìš°)
        if self.config.get('run_cross_validation', False):
            print("\nğŸ”„ êµì°¨ ê²€ì¦ ì‹¤í–‰ ì¤‘...")
            
            # ê°„ë‹¨í•œ ëª¨ë¸ ë¹Œë” í•¨ìˆ˜ ì •ì˜
            def simple_model_builder(input_shape, **kwargs):
                return self.builder.build_basic_cnn_lstm(input_shape, **kwargs)
            
            cv_results = self.trainer.cross_validate(
                simple_model_builder, 
                self.processed_data['X'], 
                self.processed_data['y']
            )
            self.results['cross_validation'] = cv_results
        
        print("âœ… í‰ê°€ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
        return self.results
    
    def run_hyperparameter_tuning(self):
        """í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹¤í–‰"""
        print("ğŸ” í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘")
        print("="*60)
        
        if self.processed_data is None:
            raise ValueError("ë°ì´í„° íŒŒì´í”„ë¼ì¸ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        
        X, y = self.processed_data['X'], self.processed_data['y']
        
        # ë°ì´í„° ë¶„í•  (íŠœë‹ìš©)
        X_train, X_val, _, y_train, y_val, _ = self.trainer.prepare_train_data(X, y)
        
        # íŠœë‹í•  íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜
        param_grid = {
            'cnn_filters': [[32, 16], [64, 32], [64, 64, 32]],
            'lstm_units': [[32, 16], [64, 32], [128, 64]],
            'dropout_rate': [0.2, 0.3, 0.4],
            'dense_units': [[32, 16], [64, 32], [128, 64]]
        }
        
        # ëª¨ë¸ ë¹Œë” í•¨ìˆ˜
        def tuning_model_builder(input_shape, **params):
            return self.builder.build_basic_cnn_lstm(input_shape, **params)
        
        # íŠœë„ˆ ì´ˆê¸°í™” ë° ì‹¤í–‰
        tuner = HyperparameterTuner(tuning_model_builder)
        tuning_results = tuner.grid_search(
            X_train, y_train, X_val, y_val, 
            param_grid, scoring='rmse'
        )
        
        # ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ì„¤ì • ì—…ë°ì´íŠ¸
        self.config.update(tuning_results['best_params'])
        
        print("âœ… í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì™„ë£Œ")
        return tuning_results
    
    def run_ensemble_pipeline(self, n_models=3):
        """ì•™ìƒë¸” ëª¨ë¸ íŒŒì´í”„ë¼ì¸"""
        print(f"ğŸ­ ì•™ìƒë¸” ëª¨ë¸ íŒŒì´í”„ë¼ì¸ ì‹œì‘ ({n_models}ê°œ ëª¨ë¸)")
        print("="*60)
        
        if self.processed_data is None:
            raise ValueError("ë°ì´í„° íŒŒì´í”„ë¼ì¸ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        
        X, y = self.processed_data['X'], self.processed_data['y']
        X_train, X_val, X_test, y_train, y_val, y_test = self.trainer.prepare_train_data(X, y)
        
        ensemble = ModelEnsemble()
        models_info = []
        
        # ë‹¤ì–‘í•œ ëª¨ë¸ êµ¬ì„±ìœ¼ë¡œ ì•™ìƒë¸” ìƒì„±
        model_configs = [
            {
                'type': 'basic',
                'cnn_filters': [64, 32],
                'lstm_units': [64, 32],
                'weight': 0.3
            },
            {
                'type': 'advanced',
                'cnn_filters': [64, 64, 32],
                'lstm_units': [128, 64],
                'use_attention': True,
                'weight': 0.4
            },
            {
                'type': 'advanced',
                'cnn_filters': [128, 64, 32],
                'lstm_units': [64, 32],
                'use_bidirectional': True,
                'weight': 0.3
            }
        ]
        
        for i, config in enumerate(model_configs[:n_models]):
            print(f"\nğŸ”¨ ì•™ìƒë¸” ëª¨ë¸ {i+1} í•™ìŠµ ì¤‘...")
            
            # ëª¨ë¸ êµ¬ì¶•
            if config['type'] == 'basic':
                model = self.builder.build_basic_cnn_lstm(
                    X.shape[1:],
                    cnn_filters=config['cnn_filters'],
                    lstm_units=config['lstm_units']
                )
            else:
                model = self.builder.build_advanced_cnn_lstm(
                    X.shape[1:],
                    cnn_filters=config['cnn_filters'],
                    lstm_units=config['lstm_units'],
                    use_attention=config.get('use_attention', False),
                    use_bidirectional=config.get('use_bidirectional', False)
                )
            
            # ì»´íŒŒì¼ ë° í•™ìŠµ
            model = self.builder.compile_model(model)
            
            # ë¹ ë¥¸ í•™ìŠµ (ì•™ìƒë¸”ìš©)
            model.fit(
                X_train, y_train,
                validation_data=(X_val, y_val),
                epochs=50,
                batch_size=32,
                verbose=0
            )
            
            # ì•™ìƒë¸”ì— ì¶”ê°€
            ensemble.add_model(model, weight=config['weight'])
            
            # ê°œë³„ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
            metrics, _, _ = self.trainer.evaluate_model(model, X_test, y_test, verbose=0)
            models_info.append({
                'model_id': i+1,
                'config': config,
                'metrics': metrics
            })
            
            print(f"  ëª¨ë¸ {i+1} RMSE: {metrics['RMSE']:.4f}")
        
        # ì•™ìƒë¸” ì˜ˆì¸¡ ë° í‰ê°€
        print(f"\nğŸ¯ ì•™ìƒë¸” ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")
        y_pred_ensemble = ensemble.predict(X_test)
        
        # ì•™ìƒë¸” ì„±ëŠ¥ í‰ê°€
        if self.processed_data['scalers'] and 'target_scaler' in self.processed_data['scalers']:
            scaler = self.processed_data['scalers']['target_scaler']
            y_true_unscaled = scaler.inverse_transform(y_test)
            y_pred_unscaled = scaler.inverse_transform(y_pred_ensemble)
        else:
            y_true_unscaled = y_test
            y_pred_unscaled = y_pred_ensemble
        
        # ì•™ìƒë¸” ì§€í‘œ ê³„ì‚°
        ensemble_metrics = {
            'RMSE': np.sqrt(mean_squared_error(y_true_unscaled, y_pred_unscaled)),
            'MAE': mean_absolute_error(y_true_unscaled, y_pred_unscaled),
            'RÂ²': r2_score(y_true_unscaled, y_pred_unscaled)
        }
        
        print("="*60)
        print("ğŸ† ì•™ìƒë¸” vs ê°œë³„ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")
        print("="*60)
        
        for info in models_info:
            print(f"ëª¨ë¸ {info['model_id']} RMSE: {info['metrics']['RMSE']:.4f}")
        
        print(f"ì•™ìƒë¸” RMSE: {ensemble_metrics['RMSE']:.4f}")
        print("="*60)
        
        # ì•™ìƒë¸” ì €ì¥
        ensemble_dir = os.path.join(self.output_dir, 'ensemble')
        os.makedirs(ensemble_dir, exist_ok=True)
        ensemble.save_ensemble(os.path.join(ensemble_dir, 'ensemble_model'))
        
        ensemble_results = {
            'ensemble_metrics': ensemble_metrics,
            'individual_models': models_info,
            'predictions': {
                'y_true': y_true_unscaled,
                'y_pred': y_pred_unscaled
            }
        }
        
        print("âœ… ì•™ìƒë¸” íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
        return ensemble_results
    
    def save_all_results(self):
        """ëª¨ë“  ê²°ê³¼ ì €ì¥"""
        print("ğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 1. ì„¤ì • ì €ì¥
        self.save_config(os.path.join(self.output_dir, f'config_{timestamp}.json'))
        
        # 2. ëª¨ë¸ ì €ì¥
        if self.model and self.config.get('save_model', True):
            model_path = os.path.join(self.output_dir, f'final_model_{timestamp}.h5')
            self.model.save(model_path)
            print(f"âœ… ëª¨ë¸ ì €ì¥: {model_path}")
        
        # 3. ê²°ê³¼ ì €ì¥
        if self.results and self.config.get('save_results', True):
            saved_files = self.trainer.save_results(
                self.results['metrics'],
                self.results['predictions']['y_true'],
                self.results['predictions']['y_pred'],
                filepath_prefix=os.path.join(self.output_dir, f'results_{timestamp}')
            )
        
        # 4. ì „ì²´ ê²°ê³¼ ìš”ì•½ ì €ì¥
        summary = {
            'timestamp': timestamp,
            'config': self.config,
            'data_info': {
                'total_samples': len(self.processed_data['X']) if self.processed_data else 0,
                'features_count': len(self.processed_data['features']) if self.processed_data else 0,
                'sequence_length': self.config['sequence_length']
            },
            'model_info': self.builder.model_config if hasattr(self.builder, 'model_config') else {},
            'performance': self.results.get('metrics', {}) if self.results else {}
        }
        
        summary_file = os.path.join(self.output_dir, f'summary_{timestamp}.json')
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"âœ… ê²°ê³¼ ìš”ì•½ ì €ì¥: {summary_file}")
        print(f"ğŸ“ ëª¨ë“  ê²°ê³¼ê°€ '{self.output_dir}' ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        return {
            'summary_file': summary_file,
            'output_directory': self.output_dir
        }
    
    def run_full_pipeline(self):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("ğŸŒŸ CNN-LSTM íƒœì–‘ê´‘ ë°œì „ ê¸°ë°˜ ì „ë ¥ ìˆ˜ìš” ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì‹œì‘")
        print("="*80)
        
        start_time = datetime.now()
        
        try:
            # 1. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (ì„ íƒì‚¬í•­)
            if self.config.get('run_hyperparameter_tuning', False):
                tuning_results = self.run_hyperparameter_tuning()
                print(f"ğŸ† ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì ìš©ë¨")
            
            # 2. ë°ì´í„° íŒŒì´í”„ë¼ì¸
            self.run_data_pipeline()
            
            # 3. ëª¨ë¸ íŒŒì´í”„ë¼ì¸
            self.run_model_pipeline()
            
            # 4. í‰ê°€ íŒŒì´í”„ë¼ì¸
            self.run_evaluation_pipeline()
            
            # 5. ì•™ìƒë¸” ì‹¤í–‰ (ì„ íƒì‚¬í•­)
            if self.config.get('run_ensemble', False):
                ensemble_results = self.run_ensemble_pipeline()
                self.results['ensemble'] = ensemble_results
            
            # 6. ê²°ê³¼ ì €ì¥
            self.save_all_results()
            
            # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
            end_time = datetime.now()
            execution_time = end_time - start_time
            
            # ìµœì¢… ê²°ê³¼ ìš”ì•½
            print("\n" + "="*80)
            print("ğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ!")
            print("="*80)
            print(f"â° ì‹¤í–‰ ì‹œê°„: {execution_time}")
            print(f"ğŸ“Š ìµœì¢… ì„±ëŠ¥ ì§€í‘œ:")
            
            if self.results and 'metrics' in self.results:
                for metric, value in self.results['metrics'].items():
                    if isinstance(value, float):
                        print(f"  {metric:>18}: {value:.4f}")
                    else:
                        print(f"  {metric:>18}: {value}")
            
            print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {self.output_dir}")
            print("="*80)
            
            return {
                'success': True,
                'results': self.results,
                'execution_time': str(execution_time),
                'output_dir': self.output_dir
            }
            
        except Exception as e:
            print(f"\nâŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            
            return {
                'success': False,
                'error': str(e),
                'execution_time': str(datetime.now() - start_time)
            }

def create_sample_config():
    """ìƒ˜í”Œ ì„¤ì • íŒŒì¼ ìƒì„±"""
    sample_config = {
        "generation_file": "Plant_1_Generation_Data.csv",
        "weather_file": "Plant_1_Weather_Sensor_Data.csv",
        "use_synthetic_data": False,
        
        "sequence_length": 24,
        "feature_selection_method": "correlation",
        "normalization_method": "minmax",
        
        "model_type": "advanced",
        "cnn_filters": [64, 64, 32],
        "lstm_units": [128, 64],
        "dense_units": [128, 64, 32],
        "dropout_rate": 0.3,
        "use_attention": True,
        "use_bidirectional": True,
        
        "epochs": 100,
        "batch_size": 32,
        "learning_rate": 0.001,
        "optimizer": "adam",
        "loss": "huber",
        "early_stopping_patience": 15,
        
        "train_ratio": 0.7,
        "val_ratio": 0.15,
        "test_ratio": 0.15,
        "shuffle": False,
        
        "random_seed": 42,
        "verbose": 1,
        "save_model": True,
        "save_results": True,
        "output_dir": "results",
        
        "run_cross_validation": False,
        "run_hyperparameter_tuning": False,
        "run_ensemble": False
    }
    
    with open('config_sample.json', 'w', encoding='utf-8') as f:
        json.dump(sample_config, f, indent=2, ensure_ascii=False)
    
    print("âœ… ìƒ˜í”Œ ì„¤ì • íŒŒì¼ ìƒì„±: config_sample.json")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="CNN-LSTM íƒœì–‘ê´‘ ë°œì „ ê¸°ë°˜ ì „ë ¥ ìˆ˜ìš” ì˜ˆì¸¡ ì‹œìŠ¤í…œ"
    )
    parser.add_argument(
        '--config', '-c', 
        help='ì„¤ì • íŒŒì¼ ê²½ë¡œ',
        default=None
    )
    parser.add_argument(
        '--create-config',
        action='store_true',
        help='ìƒ˜í”Œ ì„¤ì • íŒŒì¼ ìƒì„±'
    )
    parser.add_argument(
        '--synthetic',
        action='store_true',
        help='í•©ì„± ë°ì´í„° ì‚¬ìš©'
    )
    parser.add_argument(
        '--tune',
        action='store_true',
        help='í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹¤í–‰'
    )
    parser.add_argument(
        '--ensemble',
        action='store_true',
        help='ì•™ìƒë¸” ëª¨ë¸ ì‹¤í–‰'
    )
    parser.add_argument(
        '--output', '-o',
        help='ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬',
        default='results'
    )
    
    args = parser.parse_args()
    
    # ìƒ˜í”Œ ì„¤ì • íŒŒì¼ ìƒì„±
    if args.create_config:
        create_sample_config()
        return
    
    # íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
    pipeline = SolarPowerPredictionPipeline()
    
    # ì„¤ì • ë¡œë“œ
    if args.config:
        pipeline.load_config(args.config)
    
    # ëª…ë ¹í–‰ ì¸ìë¡œ ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ
    if args.synthetic:
        pipeline.config['use_synthetic_data'] = True
    
    if args.tune:
        pipeline.config['run_hyperparameter_tuning'] = True
    
    if args.ensemble:
        pipeline.config['run_ensemble'] = True
    
    if args.output:
        pipeline.config['output_dir'] = args.output
    
    # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    result = pipeline.run_full_pipeline()
    
    # ì‹¤í–‰ ê²°ê³¼ì— ë”°ë¥¸ ì¢…ë£Œ ì½”ë“œ
    sys.exit(0 if result['success'] else 1)

if __name__ == "__main__":
    main()
